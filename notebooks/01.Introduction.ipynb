{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An introduction to Machine Learning\n",
    "\n",
    "\n",
    "## Purpose of the course\n",
    "\n",
    "## What we will see\n",
    "\n",
    "### Some terminology\n",
    "\n",
    "## Some references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting un the environment\n",
    "\n",
    "## Installing Miniconda Python\n",
    "\n",
    "Miniconda is a free minimal installer for conda. It is a small, bootstrap version of Anaconda that includes only conda, Python, the packages they depend on, some useful ML libraries, and a small number of other useful packages, including pip, zlib and a few others. Use the conda install command to install 720+ additional conda packages from the Anaconda repository.\n",
    "\n",
    "Install scripts are available for Linux, Windows, and MacOS. Since most of use use a Mac, I will only show you how to install on this OS. Instructions are available for other platforms [here](https://conda.io/projects/conda/en/latest/user-guide/install/index.html).\n",
    "\n",
    "### Get the installer\n",
    "Installer for MacOS can be downloaded from [here](https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh).\n",
    "\n",
    "Then you just need to run \n",
    "```bash\n",
    "$ bash Miniconda3-latest-MacOSX-x86_64.sh\n",
    "```\n",
    "\n",
    "You can specify the installation directory, if you so wish. The default is `/home/$USER/miniconda3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some important libraries  (*there is a module for that...*)\n",
    "\n",
    "## `numpy`\n",
    "\n",
    "NumPy is the fundamental package for scientific computing with Python. It contains among other things:\n",
    "\n",
    " - a powerful N-dimensional array object;\n",
    " - broadcasting functions;\n",
    " - tools for integrating C/C++ and Fortran code;\n",
    " - useful linear algebra, Fourier transform, and random number capabilities.\n",
    "\n",
    "NumPy can be used as an efficient multi-dimensional container of generic data. Arbitrary data-types can be defined. Since the low-level implementation of numerical routines in NumPy is in C, the calculations are blazing fast.\n",
    "\n",
    "## `pandas`\n",
    "\n",
    "`pandas` is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,\n",
    "built on top of the Python programming language.\n",
    "`pandas` uses `numpy` under the hood to ensure all data operations are as fast as possible (if you use the right tools).\n",
    "\n",
    "Pandas is going to be that base of our data handling and we'll get to know it intimately.\n",
    "\n",
    "## `matplotlib` and `seaborn`\n",
    "\n",
    "Libraries to generate beautiful plots and graphs. We will use these to view our data.\n",
    "\n",
    "## `scipy`\n",
    "\n",
    "The SciPy ecosystem is built on top of Python and NumPy.\n",
    "\n",
    "It includes:\n",
    "\n",
    " - The SciPy library, a collection of numerical algorithms and domain-specific toolboxes, including signal processing, optimization, statistics, and much more.\n",
    " - Matplotlib, a mature and popular plotting package that provides publication-quality 2-D plotting, as well as rudimentary 3-D plotting.\n",
    "\n",
    "On this base, the SciPy ecosystem includes general and specialised tools for data management and computation, productive experimentation, and high-performance computing.\n",
    "\n",
    "## `scikit-learn`\n",
    "\n",
    "Efficient library for data analysis and predictive modeling. It provides access to a plethora of Machine LEarning algorithms using a simple and linear API.\n",
    "\n",
    "## `statsmodels`\n",
    "\n",
    "Statistical modeling, and hypothesis testing.\n",
    "\n",
    "-------------\n",
    "\n",
    "## Deep Learning toolkits\n",
    "\n",
    "### `Tensorflow`\n",
    "\n",
    "Tensorflow is an open source platform for Machine Learning developed by Google.\n",
    "\n",
    "### `Keras`\n",
    "\n",
    "\n",
    "### `Pytorch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataiku.com/static/img/learn/guide/getting-started/getting-started-with-python/logo-stack-python.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some basic syntax\n",
    "\n",
    "## `pandas` - data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `scikit-learn` - ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `keras` - deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "percent_regex = \"\\d{1,3}\\s?%\\s?[a-zA-Z]+\"\n",
    "composition_regex = \"(self|lining|contrast)\"\n",
    "\n",
    "\n",
    "def get_materials(text: str) -> List[str]:\n",
    "    materials = re.findall(percent_regex, text.lower())\n",
    "    \n",
    "    clean = [i.replace(\" \", \"\").replace(\"%\", \"% \") for i in materials]  # needs filter on accepted materials\n",
    "    components = re.findall(composition_regex, text.lower())\n",
    "    return clean, components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"\n",
    "    <ul>\n",
    "    <li>Available in Medium Wash</li>\n",
    "    <li>Denim Jumpsuit</li>\n",
    "    <li>Adjustable Straps</li>\n",
    "    <li>Lined Bust</li>\n",
    "    <li>Back Zipper</li>\n",
    "    <li>Stretch</li>\n",
    "    <li>Self: 45% Cotton 30%Rayon 23% Polyester 2% Spandex </li>\n",
    "    <li>Lining: 100% Polyester </li>\n",
    "    <li>Contrast: 50% Polyester 50% cotton</li>\n",
    "    </ul><br>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['45% cotton',\n",
       "  '30% rayon',\n",
       "  '23% polyester',\n",
       "  '2% spandex',\n",
       "  '100% polyester',\n",
       "  '50% polyester',\n",
       "  '50% cotton'],\n",
       " ['self', 'lining', 'contrast'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_materials(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_materials(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['45% cotton', '30% rayon', '23% polyester', '2% spandex']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:np.argwhere(np.cumsum([int(i.split(\"%\")[0]) for i in x]) == 100)[0][0] + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/pmascolo/Downloads/hs6 -_ customs_description - official-hs6.csv\").dropna(\n",
    "    subset=[\"customs_description\"], axis=0\n",
    ").fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"item\"] = df.item.apply(str.strip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "allowed_labels = collections.defaultdict(dict)\n",
    "\n",
    "for k in (\"material\", \"construction\", \"gender\"):\n",
    "    groups = df.groupby(\"item\")[k].unique()\n",
    "    \n",
    "    for item, v in groups.iteritems():\n",
    "        allowed_labels[item][k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = []\n",
    "\n",
    "for k, v in allowed_labels.items():\n",
    "    v[\"item_type\"] = k\n",
    "    dicts.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dicts).set_index(\"item_type\").to_json(\"allowed_labels.json\", orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ['textile']\n",
      "anorak ['wool' 'cotton' 'manmade fiber' 'textile']\n",
      "bag ['textile' 'cotton' '' 'synthetic']\n",
      "bathrobe ['cotton' 'textile' 'manmade fiber']\n",
      "bed_net ['material_irrelevant']\n",
      "bedspread ['textile']\n",
      "blanket ['textile' 'wool' 'cotton' 'synthetic']\n",
      "boots ['rubber']\n",
      "bra ['textile']\n",
      "camping goods ['textile']\n",
      "cloth ['textile']\n",
      "clothing_accessories ['']\n",
      "coin ['']\n",
      "corset ['textile']\n",
      "cufflinks ['']\n",
      "curtains ['synthetic' 'textile' 'cotton']\n",
      "diamonds ['']\n",
      "diamonds powder ['']\n",
      "dress ['wool' 'cotton' 'synthetic' 'artificial fiber' 'textile'\n",
      " 'artificial fibers']\n",
      "ensemble ['cotton' 'synthetic' 'textile' 'wool']\n",
      "footwear ['waterproof' 'rubber' 'leather' 'textile' '']\n",
      "footwear part ['']\n",
      "furnishing_article ['']\n",
      "garment ['cotton' 'synthetic' 'textile' 'rubberised' 'manmade fiber' 'felt']\n",
      "garment_parts ['material_irrelevant' '']\n",
      "girdle ['textile']\n",
      "gloves ['synthetic' 'wool' 'cotton' 'textile' 'material_irrelevant']\n",
      "gold ['']\n",
      "gold powder ['']\n",
      "handkerchief ['cotton' 'textile']\n",
      "hosiery ['textile']\n",
      "interior_furnishing_article ['' 'cotton' 'synthetic' 'textile']\n",
      "jacket ['wool' 'cotton' 'synthetic' 'textile']\n",
      "jewelry ['silver' 'precious metal' 'metal' 'platinum' '']\n",
      "life jacket ['textile']\n",
      "linen ['' 'cotton' 'manmade fiber' 'textile']\n",
      "mattress ['textile']\n",
      "metal ['']\n",
      "overcoat ['cotton' 'manmade fiber' 'textile' 'wool']\n",
      "pajamas ['cotton' 'manmade fiber' 'textile']\n",
      "pants ['wool' 'cotton' 'synthetic' 'textile']\n",
      "pearls ['']\n",
      "pearls jewelry ['' 'precious metal']\n",
      "platinum ['']\n",
      "platinum powder ['']\n",
      "precious stones ['' 'synthetic']\n",
      "precious stones powder ['']\n",
      "rags ['textile']\n",
      "refrigerator magnet ['metal']\n",
      "rug_making_kit ['textile']\n",
      "sail ['textile']\n",
      "sandal ['leather']\n",
      "scarf ['material_irrelevant' 'silk' 'wool' 'synthetic' 'artificial fibers'\n",
      " 'textile']\n",
      "scrap ['precious metal']\n",
      "shirt ['cotton' 'manmade fiber' 'textile' 'silk' 'wool']\n",
      "silver ['']\n",
      "skirt ['wool' 'cotton' 'synthetic' 'textile']\n",
      "skisuit ['']\n",
      "socks ['wool' 'cotton' 'synthetic' 'textile']\n",
      "suit ['textile' 'synthetic' 'wool' 'cotton']\n",
      "sweater ['wool' 'cashmere' 'animal_hair' 'cotton' 'manmade fiber' 'textile']\n",
      "swimsuit ['synthetic' 'textile' '']\n",
      "t-shirt ['cotton' 'textile']\n",
      "tarpaulin ['synthetic' 'textile']\n",
      "tent ['synthetic' 'textile']\n",
      "tie ['material_irrelevant' 'silk' 'manmade fiber' 'textile']\n",
      "tights ['synthetic' 'textile']\n",
      "tracksuit ['cotton' 'synthetic' 'textile' 'manmade fiber']\n",
      "underwear ['cotton' 'manmade fiber' 'textile']\n",
      "worn_article ['textile']\n"
     ]
    }
   ],
   "source": [
    "# df.groupby(\"item\")[\"material\"].unique().index\n",
    "\n",
    "for i in df.groupby(\"item\")[\"material\"].unique().iteritems():\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability p_N (current_variant) is better than other variants:\n",
    "# all variants have 2 associated parameters alpha and beta (successes, failures)\n",
    "\n",
    "\n",
    "# comparing current_variant vs. all the rest\n",
    "P = 1                                               # probability of current_variant being better than rest\n",
    "p_N = Beta(α_current_variant, β_current_variant)    # pdf of current_variant\n",
    "\n",
    "for variant in other_variants:\n",
    "    # account for all other variants\n",
    "    # removing the probability of other variants being better than current_variant\n",
    "    P -= probability_a_better_b(variant, current_variant)\n",
    "    \n",
    "\n",
    "# extra spurious term coming form the maths\n",
    "extra_term = 1\n",
    "for variant in variants:\n",
    "    partial_sum = 0\n",
    "    for i = 0 to (α_variant - 1):\n",
    "        numerator = (p_N ** i)(1 - p_N) ** β_variant\n",
    "        denominator = (β_variant + i) * Beta(1 + i, β_variant)\n",
    "        partial_sum += numerator / denominator\n",
    "\n",
    "    extra_term *= partial_sum\n",
    "\n",
    "    \n",
    "# I REEALLY do not trust this sign issue here...\n",
    "# This term should be fairly small, but I'll need to dig deeper into it\n",
    "if len(variants) % 2 == 0:\n",
    "    P += extra_term\n",
    "else:\n",
    "    P -= extra_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
